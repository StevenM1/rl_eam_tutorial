@article{Palminteri2015,
  title = {Contextual Modulation of Value Signals in Reward and Punishment Learning},
  author = {Palminteri, Stefano and Khamassi, Mehdi and Joffily, Mateus and Coricelli, Giorgio},
  year = 2015,
  journal = {Nature Communications},
  volume = {6},
  publisher = {Nature Publishing Group},
  issn = {20411723},
  doi = {10.1038/ncomms9096},
  abstract = {\copyright{} 2015 Macmillan Publishers Limited. All rights reserved. Compared with reward seeking, punishment avoidance learning is less clearly understood at both the computational and neurobiological levels. Here we demonstrate, using computational modelling and fMRI in humans, that learning option values in a relative-context-dependent-scale offers a simple computational solution for avoidance learning. The context (or state) value sets the reference point to which an outcome should be compared before updating the option value. Consequently, in contexts with an overall negative expected value, successful punishment avoidance acquires a positive value, thus reinforcing the response. As revealed by post-learning assessment of options values, contextual influences are enhanced when subjects are informed about the result of the forgone alternative (counterfactual information). This is mirrored at the neural level by a shift in negative outcome encoding from the anterior insula to the ventral striatum, suggesting that value contextualization also limits the need to mobilize an opponent punishment learning system.},
  file = {/Users/steven/Zotero/storage/NCRFCQVS/Palminteri et al 2015.pdf}
}

@article{palminteriConfirmationBiasHuman2017,
  title = {Confirmation Bias in Human Reinforcement Learning: {{Evidence}} from Counterfactual Feedback Processing},
  shorttitle = {Confirmation Bias in Human Reinforcement Learning},
  author = {Palminteri, Stefano and Lefebvre, Germain and Kilford, Emma J. and Blakemore, Sarah-Jayne},
  year = 2017,
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {8},
  pages = {e1005684},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005684},
  urldate = {2025-10-02},
  abstract = {Previous studies suggest that factual learning, that is, learning from obtained outcomes, is biased, such that participants preferentially take into account positive, as compared to negative, prediction errors. However, whether or not the prediction error valence also affects counterfactual learning, that is, learning from forgone outcomes, is unknown. To address this question, we analysed the performance of two groups of participants on reinforcement learning tasks using a computational model that was adapted to test if prediction error valence influences learning. We carried out two experiments: in the factual learning experiment, participants learned from partial feedback (i.e., the outcome of the chosen option only); in the counterfactual learning experiment, participants learned from complete feedback information (i.e., the outcomes of both the chosen and unchosen option were displayed). In the factual learning experiment, we replicated previous findings of a valence-induced bias, whereby participants learned preferentially from positive, relative to negative, prediction errors. In contrast, for counterfactual learning, we found the opposite valence-induced bias: negative prediction errors were preferentially taken into account, relative to positive ones. When considering valence-induced bias in the context of both factual and counterfactual learning, it appears that people tend to preferentially take into account information that confirms their current choice.},
  langid = {english},
  keywords = {Analysis of variance,Decision making,Economic history,Human learning,Learning,Learning curves,Optimization,Simulation and modeling},
  file = {/Users/steven/Zotero/storage/EYI96VMJ/Palminteri et al. - 2017 - Confirmation bias in human reinforcement learning Evidence from counterfactual feedback processing.pdf}
}

@article{Miletic2021,
  title = {A New Model of Decision Processing in Instrumental Learning Tasks},
  author = {Mileti{\'c}, Steven and Boag, Russell J. and Trutti, Anne C. and Stevenson, Niek and Forstmann, Birte U. and Heathcote, Andrew},
  year = 2021,
  month = jan,
  journal = {eLife},
  volume = {10},
  pages = {1--33},
  issn = {2050-084X},
  doi = {10.7554/eLife.63055},
  abstract = {Learning and decision making are interactive processes, yet cognitive modelling of error-driven learning and decision making have largely evolved separately. Recently, evidence accumulation models (EAMs) of decision making and reinforcement learning (RL) models of error-driven learning have been combined into joint RL-EAMs that can in principle address these interactions. However, we show that the most commonly used combination, based on the diffusion decision model (DDM) for binary choice, consistently fails to capture crucial aspects of response times observed during reinforcement learning. We propose a new RL-EAM based on an advantage racing diffusion (ARD) framework for choices among two or more options that not only addresses this problem but captures stimulus difficulty, speed-accuracy trade-off, and stimulus-response-mapping reversal effects. The RL-ARD avoids fundamental limitations imposed by the DDM on addressing effects of absolute values of choices, as well as extensions beyond binary choice, and provides a computationally tractable basis for wider applications.},
  keywords = {Decision making,Evidence-accumulation models,Reinforcement learning,Reversal learning,Speed-accuracy trade-off},
  file = {/Users/steven/Zotero/storage/Q9V9SSCG/Miletić et al. - 2021 - A new model of decision processing in instrumental learning tasks - eLife(2).pdf}
}


@article{jonesSequentialEffectsResponse2013,
  title = {Sequential Effects in Response Time Reveal Learning Mechanisms and Event Representations},
  author = {Jones, Matt and Curran, Tim and Mozer, Michael C. and Wilder, Matthew H.},
  year = 2013,
  month = jul,
  journal = {Psychological Review},
  volume = {120},
  number = {3},
  pages = {628--666},
  issn = {1939-1471},
  doi = {10.1037/a0033180},
  abstract = {Binary choice tasks, such as 2-alternative forced choice, show a complex yet consistent pattern of sequential effects, whereby responses and response times depend on the detailed pattern of prior stimuli going back at least 5 trials. We show this pattern is well explained by simultaneous incremental learning of 2 simple statistics of the trial sequence: the base rate and the repetition rate. Both statistics are learned by the same basic associative mechanism, but they contribute different patterns of sequential effects because they entail different representations of the trial sequence. Subtler aspects of the data that are not explained by these 2 learning processes alone are explained by their interaction, via learning from joint error correction. Specifically, the cue-competition mechanism that has explained classic findings in animal learning (e.g., blocking) appears to operate on learning of sequence statistics. We also find that learning of the base rate and repetition rate are dissociated into response and stimulus processing, respectively, as indicated by event-related potentials, manipulations of stimulus discriminability, and reanalysis of past experiments that eliminated stimuli or prior responses. Thus, sequential effects in these tasks appear to be driven by learning the response base rate and the stimulus repetition rate. Connections are discussed between these findings and previous research attempting to separate stimulus- and response-based sequential effects, and research using sequential effects to determine mental representations. We conclude that sequential effects offer a powerful means for uncovering representations and learning mechanisms.},
  langid = {english},
  pmid = {23915086},
  keywords = {Adult,Brain,Electroencephalography,Evoked Potentials,Humans,Learning,Models Psychological,Reaction Time,Time Factors,Young Adult},
  file = {/Users/steven/Zotero/storage/48YJVZQM/Jones et al. - 2013 - Sequential effects in response time reveal learnin.pdf}
}

@misc{stevensonEMC2PackageCognitive2024,
  title = {{{EMC2}}: {{An R Package}} for Cognitive Models of Choice},
  shorttitle = {{{EMC2}}},
  author = {Stevenson, Niek and Donzallaz, Michelle and Innes, Reilly James and Forstmann, Birte and Matzke, Dora and Heathcote, Andrew},
  year = 2024,
  doi = {10.31234/osf.io/2e4dq},
  urldate = {2024-10-18},
  abstract = {We introduce EMC2, an R package for the Bayesian hierarchical analysisof cognitive models of choice. EMC2 bridges the gap between standardregression analyses and cognitive modeling through linear-model specifica-tions for each type of cognitive-model parameter. The flexible implemen-tation of the linear modelling language allows users to map model parame-ters directly to complicated designs and hypotheses. EMC2 implementsrecent developments in Bayesian parameter estimation and hypothesistesting, including powerful and efficient sampling and marginal likelihoodestimation algorithms, so it is computationally feasible to estimate manydifferent cognitive models, and perform inference among them. Using twoleading evidence-accumulation models, we illustrate how EMC2 providesa workflow that makes it easy to specify diverse parameterisations and in-formative priors, and to evaluate, refine, compare, and interpret models.},
  copyright = {cc by},
  file = {/Users/steven/Zotero/storage/LF3QUAXZ/Stevenson et al. - 2024 - EMC2 An R Package for cognitive models of choic.pdf}
}

@article{mileticExplainingMultiScaleChoice2025,
  title = {Explaining {{Multi-Scale Choice Dynamics}}},
  author = {Mileti{\'c}, Steven and Stevenson, Niek and Eidels, Ami and Matzke, Dora and Forstmann, Birte and Heathcote, Andrew},
  year = 2025,
  journal = {Psychological Review},
  doi = {10.1037/rev0000581},
  urldate = {2025-09-01},
  abstract = {Sequences of choice response times exhibit ubiquitous and strong multiscale dynamics (i.e., sequential dependencies across a broad range of temporal scales). Despite their pervasive nature, multiscale dynamics are poorly understood. We show that dynamics in the seconds to minutes range can be explained by the superposition of several distinct learning and control mechanisms. Each mechanism learns a representation of the structure of the choice environment and/or an aspect of the decision-maker's ability. These representations are updated after each choice and used to control the next decision by modulating the parameters of an evidence accumulation process with subsecond range dynamics that determine individual choices. We link these mechanisms to three major foci in the experimental study of sequential dependencies: stimulus history, error-related, and hard--easy effects. This account provides a detailed explanation of both multiscale dynamics of choice sequences, and the three effects, at the group and individual levels.},
    copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
    langid = {english},
    file = {/Users/steven/Zotero/storage/B6WI46GD/Miletic et al. - 2024 - Explaining Multi-Scale Choice Dynamics.pdf}
  }
  
  @article{Wagenmakers2004a,
    title = {Estimation and Interpretation of 1/F{$\alpha$} Noise in Human Cognition},
    author = {Wagenmakers, Eric-Jan and Farrell, Simon and Ratcliff, Roger},
    year = 2004,
    journal = {Psychonomic Bulletin \& Review},
    volume = {11},
    number = {4},
    pages = {579--615},
    issn = {10699384},
    doi = {10.3758/BF03196615},
    abstract = {Recent analyses of serial correlations in cognitive tasks have provided preliminary evidence of the presence of a particular form of long-range serial dependence known as 1/f noise. It has been argued that long-range dependence has been largely ignored in mainstream cognitive psychology even though it accounts for a substantial proportion of variability in behavior (see, e.g., Gilden, 1997, 2001). In this article, we discuss the defining characteristics of long-range dependence and argue that claims about its presence need to be evaluated by testing against the alternative hypothesis of short-range dependence. For the data from three experiments, we accomplish such tests with autoregressive fractionally integrated moving-average time series modeling. We find that long-range serial dependence in these experiments can be explained by any of several mechanisms, including mixtures of a small number of short-range processes. Copyright 2004 Psychonomic Society, Inc.},
    pmid = {15581115},
    file = {/Users/steven/Zotero/storage/VCJBU9MU/Wagenmakers, Farrell, Ratcliff - 2004 - Estimation and interpretation of 1fα noise in human cognition - Psychonomic Bulletin and Review.pdf}
  }
  